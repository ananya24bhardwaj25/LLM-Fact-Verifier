# LLM-Fact-Verifier
About Section:
This project is a local fact-checking assistant powered by the Mistral language model (via Ollama), FAISS vector search, and an intuitive Streamlit interface. It enables users to input claims and retrieve relevant factual evidence from a custom dataset.

ğŸ” Key Features:

Embeds and indexes custom factual data with SentenceTransformers and FAISS

Runs completely offline with Mistral LLM via Ollama â€” no external APIs required

Provides an easy-to-use web interface for fact verification via Streamlit

Supports classification of claims as Supported, Contradicted, or Unverifiable

# Project Structure

â”œâ”€â”€ appdemo.py            #  UI

â”œâ”€â”€ embed_store.py        # Embedding + FAISS storage logic

â”œâ”€â”€ verifier.py           # Command-line interface (optional)

â”œâ”€â”€ facts.csv             # Local factual data

â”œâ”€â”€ facts_embeddings.pkl  # Pickled embeddings

â”œâ”€â”€ faiss.index           # FAISS index for fact search

â”œâ”€â”€ requirements.txt      # Python dependencies

â””â”€â”€ README.md             # You're here!


# How it Works

The model embeds factual data from facts.csv using SentenceTransformers.

FAISS creates a vector index to allow similarity-based retrieval.

A user's claim is embedded and compared to the index.

The top-k similar facts are passed to the LLM (mistral) via Ollama.

The model returns a verdict: SUPPORTED, CONTRADICTED, or UNVERIFIABLE.
